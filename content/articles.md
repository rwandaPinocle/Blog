---
title: "Interesting Articles And Books"
date: 2024-06-11T11:26:08-07:00
draft: false
---
# Machine Learning and Artificial Intelligence

[Dive into Deep Learning](https://d2l.ai/index.html):
A free book on contemporary deep learning, with code examples in PyTorch, Numpy, JAX and Tensorflow

[ML Compiler class](https://mlc.ai/summer22/schedule):
A class by the creators of Apache TVM about the theory behind ML compilers.

[Refusal in Language Models is Mediated by a Single Direction](https://arxiv.org/abs/2406.11717):
The authors find a one dimensional subspace in the activation space of multiple LLMs that controls refusal.
Subtracting it causes the models to comply with harmful instructions and adding it causes it to refuse harmless instructions.

[LLama.mojo benchmarks](https://engiware.com/benchmark/llama2-ports-extensive-benchmarks-mac-m1-max.html):
Llama2.mojo is on par with Llama.cpp single threaded and beats Llama.c and Llama.cpp on multithreaded.

[Uncensor any LLM with abliteration](https://huggingface.co/blog/mlabonne/abliteration):
The censorship behavior of LLMs can be modified by finding the mean normalized direction of the layer activations and adding or subtracting that during inference.

[AI Will Become Mathematicians Co-Pilot](https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/):
Terry Tao explains how proof checkers, specifically Lean, and AI are changing the way mathematicians work

[Mapping the Mind of a Large Language Model, by Anthropic](https://www.anthropic.com/news/mapping-mind-language-model):
Interpreting individual activations inside of LLMs

[A Recipe for Training Neural Networks, by Andrej Karpathy](https://karpathy.github.io/2019/04/25/recipe/)

[Lessons from a year of building with LLMs](https://applied-llms.org/)

Training on a single gpu
 - https://huggingface.co/docs/transformers/en/perf_train_gpu_one
 - https://magazine.sebastianraschka.com/p/understanding-large-language-models
 - https://towardsdatascience.com/editing-text-in-images-with-ai-03dee75d8b9c
 - https://github.com/Mozilla-Ocho/llamafile

[How I keep up with ai progress](https://blog.nilenso.com/blog/2025/06/23/how-i-keep-up-with-ai-progress)

[Simon Wilson's Blog](https://simonwillison.net/)

# Graphics

[Exponentially Better Rotations](https://thenumb.at/Exponential-Rotations/):
Explains the different methods of handling rotations in graphics, with very nifty demos.

# Misc

[Spaced repetition for teaching two-year olds how to read](https://chrislakin.blog/p/spaced-repetition-for-teaching-two):
An interview with a father who taught his 2 year old daughter to read with Anki.

